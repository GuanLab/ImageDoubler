{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from glob import glob\n",
    "from collections import Counter\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"expression/results/solo/solo_imgExtra_noMissing.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.35602094240837695,\n",
       " 0.3408521303258145,\n",
       " 0.2765957446808511,\n",
       " 0.3557951482479784,\n",
       " 0.33658536585365856,\n",
       " 0.3484848484848485,\n",
       " 0.3486682808716707,\n",
       " 0.34549878345498786,\n",
       " 0.3652173913043478]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v[\"f1_score\"] for k, v in adata.uns.items() if \"f1_score\" in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agreements\n",
    "labeler1_target = pd.read_csv(\"crop_target/targets.csv\")\n",
    "labeler2_target = pd.read_csv(\"crop_target/xinya_targets.csv\")\n",
    "combine = pd.merge(labeler1_target, labeler2_target, on=\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>cell_num_x</th>\n",
       "      <th>class_x</th>\n",
       "      <th>difficult_x</th>\n",
       "      <th>cell_num_y</th>\n",
       "      <th>class_y</th>\n",
       "      <th>difficult_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image10_25_15</td>\n",
       "      <td>1</td>\n",
       "      <td>Singlet</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Singlet</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image10_9_18</td>\n",
       "      <td>1</td>\n",
       "      <td>Singlet</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Singlet</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image10_4_3</td>\n",
       "      <td>1</td>\n",
       "      <td>Singlet</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Singlet</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image10_32_12</td>\n",
       "      <td>1</td>\n",
       "      <td>Singlet</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Singlet</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image10_23_4</td>\n",
       "      <td>0</td>\n",
       "      <td>Missing</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Singlet</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5293</th>\n",
       "      <td>Image5_11_10</td>\n",
       "      <td>1</td>\n",
       "      <td>Singlet</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Singlet</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5294</th>\n",
       "      <td>Image5_24_20</td>\n",
       "      <td>0</td>\n",
       "      <td>Missing</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Missing</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5295</th>\n",
       "      <td>Image5_39_11</td>\n",
       "      <td>0</td>\n",
       "      <td>Missing</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Missing</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5296</th>\n",
       "      <td>Image5_7_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Singlet</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Singlet</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5297</th>\n",
       "      <td>Image5_7_2</td>\n",
       "      <td>1</td>\n",
       "      <td>Singlet</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Singlet</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5298 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           image_id  cell_num_x  class_x  difficult_x  cell_num_y  class_y  \\\n",
       "0     Image10_25_15           1  Singlet        False           1  Singlet   \n",
       "1      Image10_9_18           1  Singlet        False           1  Singlet   \n",
       "2       Image10_4_3           1  Singlet        False           1  Singlet   \n",
       "3     Image10_32_12           1  Singlet        False           1  Singlet   \n",
       "4      Image10_23_4           0  Missing        False           1  Singlet   \n",
       "...             ...         ...      ...          ...         ...      ...   \n",
       "5293   Image5_11_10           1  Singlet        False           1  Singlet   \n",
       "5294   Image5_24_20           0  Missing        False           0  Missing   \n",
       "5295   Image5_39_11           0  Missing        False           0  Missing   \n",
       "5296     Image5_7_8           1  Singlet        False           1  Singlet   \n",
       "5297     Image5_7_2           1  Singlet        False           1  Singlet   \n",
       "\n",
       "      difficult_y  \n",
       "0           False  \n",
       "1           False  \n",
       "2           False  \n",
       "3           False  \n",
       "4           False  \n",
       "...           ...  \n",
       "5293        False  \n",
       "5294        False  \n",
       "5295        False  \n",
       "5296        False  \n",
       "5297        False  \n",
       "\n",
       "[5298 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7727537922987164"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine.shape[0]/ labeler2_target.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9363910909777274"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(combine.cell_num_x == combine.cell_num_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show that model has enough samples to learn different classes\n",
    "def count_classes(split_file):\n",
    "    with open(split_file) as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    missing, cells = 0, 0\n",
    "    for line in lines:\n",
    "        num_cols = len(line.strip().split())\n",
    "        if num_cols == 1:\n",
    "            missing += 1\n",
    "        elif num_cols > 1:\n",
    "            cells += 1\n",
    "    \n",
    "    return missing, cells\n",
    "\n",
    "# Faster-RCNN-Ensemble/train_val_split/loocv/Image1/2007_train_5.txt\n",
    "records = []\n",
    "for split_file in glob(\"Faster-RCNN-Ensemble/train_val_split/loocv/Image*/2007_train_*.txt\"):\n",
    "    fold = str(split_file.split(\"/\")[-2])\n",
    "    model = int(os.path.basename(split_file).split(\".\")[0].split(\"_\")[-1])\n",
    "    missing, cells = count_classes(split_file)\n",
    "    records.append([fold, model, missing, cells])\n",
    "\n",
    "records = pd.DataFrame(records, columns=[\"fold\", \"model\", \"missing\", \"cells\"])\n",
    "records.to_csv(\"./Figure_revision/supp_count_loocv_classes.csv\", index=False)\n",
    "\n",
    "records = []\n",
    "for split_file in glob(\"Faster-RCNN-Ensemble-Xinya/train_val_split/loocv/Image*/2007_train_*.txt\"):\n",
    "    fold = str(split_file.split(\"/\")[-2])\n",
    "    model = int(os.path.basename(split_file).split(\".\")[0].split(\"_\")[-1])\n",
    "    missing, cells = count_classes(split_file)\n",
    "    records.append([fold, model, missing, cells])\n",
    "\n",
    "records = pd.DataFrame(records, columns=[\"fold\", \"model\", \"missing\", \"cells\"])\n",
    "records.to_csv(\"./Figure_revision/supp_count_loocv_classes_labeler2.csv\", index=False)\n",
    "\n",
    "records = []\n",
    "for split_file in glob(\"Faster-RCNN-Ensemble/train_val_split/for_expression/2007_train_*.txt\"):\n",
    "    model = int(os.path.basename(split_file).split(\".\")[0].split(\"_\")[-1])\n",
    "    missing, cells = count_classes(split_file)\n",
    "    records.append([model, missing, cells])\n",
    "\n",
    "records = pd.DataFrame(records, columns=[\"model\", \"missing\", \"cells\"])\n",
    "records.to_csv(\"./Figure_revision/supp_count_resolution_classes.csv\", index=False)\n",
    "\n",
    "records = []\n",
    "for split_file in glob(\"Faster-RCNN-Ensemble-Xinya/train_val_split/for_expression/2007_train_*.txt\"):\n",
    "    model = int(os.path.basename(split_file).split(\".\")[0].split(\"_\")[-1])\n",
    "    missing, cells = count_classes(split_file)\n",
    "    records.append([model, missing, cells])\n",
    "\n",
    "records = pd.DataFrame(records, columns=[\"model\", \"missing\", \"cells\"])\n",
    "records.to_csv(\"./Figure_revision/supp_count_resolution_classes_labeler2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_classes(split_file):\n",
    "    with open(split_file) as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    missing, cells, singlet, doublet = 0, 0, 0, 0\n",
    "    image_sets = set()\n",
    "    for line in lines:\n",
    "        contents = line.strip().split()\n",
    "        image_set = contents[0].split(\"/\")[-1].split(\"_\")[0]\n",
    "        image_sets.add(image_set)\n",
    "        num_cols = len(contents)\n",
    "        if num_cols == 1:\n",
    "            missing += 1\n",
    "        elif num_cols == 2:\n",
    "            cells += 1\n",
    "            singlet += 1\n",
    "        elif num_cols > 2:\n",
    "            cells += 1\n",
    "            doublet += 1\n",
    "    \n",
    "    return \", \".join(list(image_sets)), missing, cells, singlet, doublet\n",
    "\n",
    "def count_test_classes(target, fold):\n",
    "    if fold == \"low_resolution\":\n",
    "        target = target[(target.image_id.str.contains(\"Image5_\") | target.image_id.str.contains(\"Image11_\")) & \n",
    "                        (target.difficult == False)]\n",
    "    elif fold.startswith(\"Image\"):\n",
    "        target = target[target.image_id.str.contains(fold+\"_\") & (target.difficult == False)]\n",
    "    missing = target[target.cell_num == 0].shape[0]\n",
    "    cells = target[target.cell_num > 0].shape[0]\n",
    "    singlet = target[target.cell_num == 1].shape[0]\n",
    "    doublet = target[target.cell_num > 1].shape[0]\n",
    "    return missing, cells, singlet, doublet\n",
    "\n",
    "# Faster-RCNN-Ensemble/train_val_split/loocv/Image1/2007_train_5.txt\n",
    "records = []\n",
    "for train_file in glob(\"Faster-RCNN-Ensemble/train_val_split/loocv/Image*/2007_train_*.txt\"):\n",
    "    val_file = train_file.replace(\"2007_train\", \"2007_val\")\n",
    "    fold = str(train_file.split(\"/\")[-2])\n",
    "    model = int(os.path.basename(train_file).split(\".\")[0].split(\"_\")[-1])\n",
    "    train_sets, train_missing, train_cells, train_singlet, train_doublet = count_classes(train_file)\n",
    "    val_sets, val_missing, val_cells, val_singlet, val_doublet = count_classes(val_file)\n",
    "    test_missing, test_cells, test_singlet, test_doublet = count_test_classes(labeler1_target, fold)\n",
    "    records.append([fold, model, \n",
    "                    train_sets, train_missing, train_cells, train_singlet, train_doublet, \n",
    "                    val_sets, val_missing, val_cells, val_singlet, val_doublet,\n",
    "                    test_missing, test_cells, test_singlet, test_doublet])\n",
    "for train_file in glob(\"Faster-RCNN-Ensemble/train_val_split/for_expression/2007_train_*.txt\"):\n",
    "    fold = \"low_resolution\"\n",
    "    model = int(os.path.basename(train_file).split(\".\")[0].split(\"_\")[-1])\n",
    "    train_sets, train_missing, train_cells, train_singlet, train_doublet = count_classes(train_file)\n",
    "    val_sets, val_missing, val_cells, val_singlet, val_doublet = count_classes(train_file.replace(\"2007_train\", \"2007_val\"))\n",
    "    test_missing, test_cells, test_singlet, test_doublet = count_test_classes(labeler1_target, fold)\n",
    "    records.append([fold, model, \n",
    "                    train_sets, train_missing, train_cells, train_singlet, train_doublet, \n",
    "                    val_sets, val_missing, val_cells, val_singlet, val_doublet,\n",
    "                    test_missing, test_cells, test_singlet, test_doublet])\n",
    "records = pd.DataFrame(records, columns=[\"fold\", \"model\", \n",
    "                                         \"train_image_sets\", \"train_missing\", \"train_cells\", \"train_singlet\", \"train_doublet\",\n",
    "                                         \"val_image_sets\", \"val_missing\", \"val_cells\", \"val_singlet\", \"val_doublet\",\n",
    "                                         \"test_missing\", \"test_cells\", \"test_singlet\", \"test_doublet\"])\n",
    "records.to_csv(\"./Figure_revision/supp_summary_cv_labeler1.tsv\", index=False, sep=\"\\t\")\n",
    "\n",
    "records = []\n",
    "for train_file in glob(\"Faster-RCNN-Ensemble-Xinya/train_val_split/loocv/Image*/2007_train_*.txt\"):\n",
    "    val_file = train_file.replace(\"2007_train\", \"2007_val\")\n",
    "    fold = str(train_file.split(\"/\")[-2])\n",
    "    model = int(os.path.basename(train_file).split(\".\")[0].split(\"_\")[-1])\n",
    "    train_sets, train_missing, train_cells, train_singlet, train_doublet = count_classes(train_file)\n",
    "    val_sets, val_missing, val_cells, val_singlet, val_doublet = count_classes(val_file)\n",
    "    test_missing, test_cells, test_singlet, test_doublet = count_test_classes(labeler1_target, fold)\n",
    "    records.append([fold, model, \n",
    "                    train_sets, train_missing, train_cells, train_singlet, train_doublet, \n",
    "                    val_sets, val_missing, val_cells, val_singlet, val_doublet,\n",
    "                    test_missing, test_cells, test_singlet, test_doublet])\n",
    "for train_file in glob(\"Faster-RCNN-Ensemble-Xinya/train_val_split/for_expression/2007_train_*.txt\"):\n",
    "    fold = \"low_resolution\"\n",
    "    model = int(os.path.basename(train_file).split(\".\")[0].split(\"_\")[-1])\n",
    "    train_sets, train_missing, train_cells, train_singlet, train_doublet = count_classes(train_file)\n",
    "    val_sets, val_missing, val_cells, val_singlet, val_doublet = count_classes(train_file.replace(\"2007_train\", \"2007_val\"))\n",
    "    test_missing, test_cells, test_singlet, test_doublet = count_test_classes(labeler1_target, fold)\n",
    "    records.append([fold, model, \n",
    "                    train_sets, train_missing, train_cells, train_singlet, train_doublet, \n",
    "                    val_sets, val_missing, val_cells, val_singlet, val_doublet,\n",
    "                    test_missing, test_cells, test_singlet, test_doublet])\n",
    "records = pd.DataFrame(records, columns=[\"fold\", \"model\", \n",
    "                                         \"train_image_sets\", \"train_missing\", \"train_cells\", \"train_singlet\", \"train_doublet\",\n",
    "                                         \"val_image_sets\", \"val_missing\", \"val_cells\", \"val_singlet\", \"val_doublet\",\n",
    "                                         \"test_missing\", \"test_cells\", \"test_singlet\", \"test_doublet\"])\n",
    "records.to_csv(\"./Figure_revision/supp_summary_cv_labeler2.tsv\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loocv(model_folder):\n",
    "    columns = [\"thresh\", \"acc\", \"balance_acc\", \"weight_f1\", \"avg_f1\", \"model\", \"cv_type\", \"testset\", \"model_id\"]\n",
    "    \n",
    "    loocv_performances = []\n",
    "    glob_path = f\"./{model_folder}/map_out/loocv/*/performance*.json\"\n",
    "    for json_file in glob(glob_path):\n",
    "        image_id = json_file.split(\"/\")[-2]\n",
    "        base_name = os.path.splitext(os.path.basename(json_file))[0]\n",
    "        model_id = \"ensemble\" if \"model\" not in base_name else base_name.split(\"-\")[-1]\n",
    "        with open(json_file) as f:\n",
    "            res_json = json.load(f)\n",
    "        for k, subd in res_json.items():\n",
    "            record = [float(k), subd[\"accuracy\"], subd[\"balanced_accuracy\"], subd[\"weighted_f1\"], subd[\"avg_f1\"]]\n",
    "            # model, cv_type, testset, model_id\n",
    "            record += [model_folder, \"loocv\", image_id, model_id]\n",
    "            loocv_performances.append(record)        \n",
    "    loocv_performances = pd.DataFrame(loocv_performances, columns=columns)\n",
    "\n",
    "    glob_path = f\"./{model_folder}/map_out/loocv/avg_scores*.tsv\"\n",
    "    for tsv_file in glob(glob_path):\n",
    "        base_name = os.path.splitext(os.path.basename(tsv_file))[0]\n",
    "        model_id = \"ensemble\" if \"model\" not in base_name else base_name.split(\"_\")[-1]\n",
    "        loocv_overall = pd.read_table(tsv_file, sep=\"\\t\", header=None,\n",
    "                                      names=[\"thresh\", \"acc\", \"balance_acc\", \"weight_f1\", \"avg_f1\"])\n",
    "        loocv_overall[\"model\"] = model_folder\n",
    "        loocv_overall[\"cv_type\"] = \"loocv\"\n",
    "        loocv_overall[\"testset\"] = \"average\"\n",
    "        loocv_overall[\"model_id\"] = model_id\n",
    "        loocv_performances = pd.concat([loocv_performances, loocv_overall], ignore_index=True)\n",
    "\n",
    "    return loocv_performances\n",
    "\n",
    "def get_cross_resolution(model_folder):\n",
    "    cross_reso_performances = pd.DataFrame()\n",
    "    glob_path = f\"./{model_folder}/map_out/for_expression/performance*.tsv\"\n",
    "    \n",
    "    for tsv_file in glob(glob_path):\n",
    "        base_name = os.path.splitext(os.path.basename(tsv_file))[0]\n",
    "        model_id = \"ensemble\" if \"model\" not in base_name else base_name.split(\"-\")[-1]\n",
    "        performances = pd.read_table(\n",
    "            tsv_file, sep=\"\\t\", header=None, \n",
    "            names=[\"thresh\", \"acc\", \"balance_acc\", \"weight_f1\", \"avg_f1\"])\n",
    "        performances[\"model\"] = model_folder\n",
    "        performances[\"cv_type\"] = \"cross-resolution\"\n",
    "        performances[\"testset\"] = \"low-resolution\"\n",
    "        performances[\"model_id\"] = model_id\n",
    "        cross_reso_performances = pd.concat([cross_reso_performances, performances])\n",
    "    return cross_reso_performances\n",
    "\n",
    "# show the performances of single models and ensemble model\n",
    "records = get_loocv(\"Faster-RCNN-Ensemble\")\n",
    "records.to_csv(\"./Figure_revision/supp_loocv_singleVSensemble.csv\", index=False)\n",
    "\n",
    "records = get_cross_resolution(\"Faster-RCNN-Ensemble\")\n",
    "records.to_csv(\"./Figure_revision/supp_resolution_singleVSensemble.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss info\n",
    "train_losses_file_loocv = glob(\"Faster-RCNN-Ensemble/logs/loocv/Image*/loss_2023_12_*/epoch_loss_*.txt\")\n",
    "val_losses_file_loocv = glob(\"Faster-RCNN-Ensemble/logs/loocv/Image*/loss_2023_12_*/epoch_val_loss_*.txt\")\n",
    "train_losses_file_reso = glob(\"Faster-RCNN-Ensemble/logs/for_expression/loss_2023_11_*/epoch_loss_*.txt\")\n",
    "val_losses_file_reso = glob(\"Faster-RCNN-Ensemble/logs/for_expression/loss_2023_11_*/epoch_val_loss_*.txt\")\n",
    "\n",
    "records = []\n",
    "for file in train_losses_file_loocv:\n",
    "    fold = file.split(\"/\")[3]\n",
    "    loss_id = file.split(\"/\")[4]\n",
    "    cv_type = \"loocv\"\n",
    "    loss_type = \"train\"\n",
    "    with open(file) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            loss = float(line.strip().split()[0])\n",
    "            records.append([fold, loss_id, cv_type, loss_type, i, loss])\n",
    "for file in val_losses_file_loocv:\n",
    "    fold = file.split(\"/\")[3]\n",
    "    loss_id = file.split(\"/\")[4]\n",
    "    cv_type = \"loocv\"\n",
    "    loss_type = \"val\"\n",
    "    with open(file) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            loss = float(line.strip().split()[0])\n",
    "            records.append([fold, loss_id, cv_type, loss_type, i, loss])\n",
    "for file in train_losses_file_reso:\n",
    "    fold = \"low_resolution\"\n",
    "    loss_id = file.split(\"/\")[3]\n",
    "    cv_type = \"cross-resolution\"\n",
    "    loss_type = \"train\"\n",
    "    with open(file) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            loss = float(line.strip().split()[0])\n",
    "            records.append([fold, loss_id, cv_type, loss_type, i, loss])\n",
    "for file in val_losses_file_reso:\n",
    "    fold = \"low_resolution\"\n",
    "    loss_id = file.split(\"/\")[3]\n",
    "    cv_type = \"cross-resolution\"\n",
    "    loss_type = \"val\"\n",
    "    with open(file) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            loss = float(line.strip().split()[0])\n",
    "            records.append([fold, loss_id, cv_type, loss_type, i, loss])\n",
    "            \n",
    "records = pd.DataFrame(records, columns=[\"fold\", \"loss_id\", \"cv_type\", \"loss_type\", \"epoch\", \"loss\"])\n",
    "\n",
    "records[\"model_id\"] = 0\n",
    "for fold in records[\"fold\"].unique():\n",
    "    for epoch in records[\"epoch\"].unique():\n",
    "        for loss_type in records[\"loss_type\"].unique():\n",
    "            idx = records[(records[\"fold\"] == fold) & (records[\"epoch\"] == epoch) & (records[\"loss_type\"] == loss_type)].index\n",
    "            records.loc[idx, \"model_id\"] = range(1, len(idx)+1)\n",
    "            \n",
    "records.to_csv(\"./Figure_revision/supp_loss_info_labeler1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss info\n",
    "train_losses_file_loocv = glob(\"Faster-RCNN-Ensemble-Xinya/logs/loocv/Image*/loss_2024_01_1*/epoch_loss_*.txt\")\n",
    "val_losses_file_loocv = glob(\"Faster-RCNN-Ensemble-Xinya/logs/loocv/Image*/loss_2024_01_1*/epoch_val_loss_*.txt\")\n",
    "# train_losses_file_reso = glob(\"Faster-RCNN-Ensemble-Xinya/logs/for_expression/*/epoch_loss_*.txt\")\n",
    "# val_losses_file_reso = glob(\"Faster-RCNN-Ensemble-Xinya/logs/for_expression/*/epoch_val_loss_*.txt\")\n",
    "\n",
    "records = []\n",
    "for file in train_losses_file_loocv:\n",
    "    fold = file.split(\"/\")[3]\n",
    "    loss_id = file.split(\"/\")[4]\n",
    "    cv_type = \"loocv\"\n",
    "    loss_type = \"train\"\n",
    "    with open(file) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            loss = float(line.strip().split()[0])\n",
    "            records.append([fold, loss_id, cv_type, loss_type, i, loss])\n",
    "for file in val_losses_file_loocv:\n",
    "    fold = file.split(\"/\")[3]\n",
    "    loss_id = file.split(\"/\")[4]\n",
    "    cv_type = \"loocv\"\n",
    "    loss_type = \"val\"\n",
    "    with open(file) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            loss = float(line.strip().split()[0])\n",
    "            records.append([fold, loss_id, cv_type, loss_type, i, loss])\n",
    "         \n",
    "records = pd.DataFrame(records, columns=[\"fold\", \"loss_id\", \"cv_type\", \"loss_type\", \"epoch\", \"loss\"])\n",
    "\n",
    "records[\"model_id\"] = 0\n",
    "for fold in records[\"fold\"].unique():\n",
    "    for epoch in records[\"epoch\"].unique():\n",
    "        for loss_type in records[\"loss_type\"].unique():\n",
    "            idx = records[(records[\"fold\"] == fold) & (records[\"epoch\"] == epoch) & (records[\"loss_type\"] == loss_type)].index\n",
    "            records.loc[idx, \"model_id\"] = range(1, len(idx)+1)\n",
    "            \n",
    "records.to_csv(\"./Figure_revision/supp_loss_info_labeler2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = get_loocv(\"Faster-RCNN-noAug\")\n",
    "records.to_csv(\"./Figure_revision/supp_loocv_noAug.csv\", index=False)\n",
    "\n",
    "records = get_loocv(\"Faster-RCNN\")\n",
    "records.to_csv(\"./Figure_revision/supp_loocv_wAug.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\"Singlet\", \"Singlet\", \"Doublet\", \"Doublet\", \"Missing\"]\n",
    "counter = Counter(data)\n",
    "class_order = {\"Doublet\": 0, \"Singlet\": 1, \"Missing\": 2}\n",
    "sorted_items = sorted(counter.items(), key=lambda item: (-item[1], class_order[item[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thresh</th>\n",
       "      <th>acc</th>\n",
       "      <th>balance_acc</th>\n",
       "      <th>weight_f1</th>\n",
       "      <th>avg_f1</th>\n",
       "      <th>model</th>\n",
       "      <th>cv_type</th>\n",
       "      <th>testset</th>\n",
       "      <th>model_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.901114</td>\n",
       "      <td>0.910930</td>\n",
       "      <td>0.912522</td>\n",
       "      <td>0.901114</td>\n",
       "      <td>Faster-RCNN-noAug</td>\n",
       "      <td>loocv</td>\n",
       "      <td>Image10</td>\n",
       "      <td>ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.912256</td>\n",
       "      <td>0.904280</td>\n",
       "      <td>0.921030</td>\n",
       "      <td>0.912256</td>\n",
       "      <td>Faster-RCNN-noAug</td>\n",
       "      <td>loocv</td>\n",
       "      <td>Image10</td>\n",
       "      <td>ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.916435</td>\n",
       "      <td>0.893184</td>\n",
       "      <td>0.924276</td>\n",
       "      <td>0.916435</td>\n",
       "      <td>Faster-RCNN-noAug</td>\n",
       "      <td>loocv</td>\n",
       "      <td>Image10</td>\n",
       "      <td>ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.923398</td>\n",
       "      <td>0.883079</td>\n",
       "      <td>0.929253</td>\n",
       "      <td>0.923398</td>\n",
       "      <td>Faster-RCNN-noAug</td>\n",
       "      <td>loocv</td>\n",
       "      <td>Image10</td>\n",
       "      <td>ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.924791</td>\n",
       "      <td>0.853631</td>\n",
       "      <td>0.928787</td>\n",
       "      <td>0.924791</td>\n",
       "      <td>Faster-RCNN-noAug</td>\n",
       "      <td>loocv</td>\n",
       "      <td>Image10</td>\n",
       "      <td>ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.931548</td>\n",
       "      <td>0.910976</td>\n",
       "      <td>0.935748</td>\n",
       "      <td>0.931548</td>\n",
       "      <td>Faster-RCNN-noAug</td>\n",
       "      <td>loocv</td>\n",
       "      <td>average</td>\n",
       "      <td>ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.937502</td>\n",
       "      <td>0.909570</td>\n",
       "      <td>0.940199</td>\n",
       "      <td>0.937502</td>\n",
       "      <td>Faster-RCNN-noAug</td>\n",
       "      <td>loocv</td>\n",
       "      <td>average</td>\n",
       "      <td>ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.941130</td>\n",
       "      <td>0.909653</td>\n",
       "      <td>0.942723</td>\n",
       "      <td>0.941130</td>\n",
       "      <td>Faster-RCNN-noAug</td>\n",
       "      <td>loocv</td>\n",
       "      <td>average</td>\n",
       "      <td>ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.943117</td>\n",
       "      <td>0.897548</td>\n",
       "      <td>0.943203</td>\n",
       "      <td>0.943117</td>\n",
       "      <td>Faster-RCNN-noAug</td>\n",
       "      <td>loocv</td>\n",
       "      <td>average</td>\n",
       "      <td>ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.932632</td>\n",
       "      <td>0.858044</td>\n",
       "      <td>0.930085</td>\n",
       "      <td>0.932632</td>\n",
       "      <td>Faster-RCNN-noAug</td>\n",
       "      <td>loocv</td>\n",
       "      <td>average</td>\n",
       "      <td>ensemble</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    thresh       acc  balance_acc  weight_f1    avg_f1              model  \\\n",
       "0      0.3  0.901114     0.910930   0.912522  0.901114  Faster-RCNN-noAug   \n",
       "1      0.4  0.912256     0.904280   0.921030  0.912256  Faster-RCNN-noAug   \n",
       "2      0.5  0.916435     0.893184   0.924276  0.916435  Faster-RCNN-noAug   \n",
       "3      0.6  0.923398     0.883079   0.929253  0.923398  Faster-RCNN-noAug   \n",
       "4      0.7  0.924791     0.853631   0.928787  0.924791  Faster-RCNN-noAug   \n",
       "..     ...       ...          ...        ...       ...                ...   \n",
       "61     0.4  0.931548     0.910976   0.935748  0.931548  Faster-RCNN-noAug   \n",
       "62     0.5  0.937502     0.909570   0.940199  0.937502  Faster-RCNN-noAug   \n",
       "63     0.6  0.941130     0.909653   0.942723  0.941130  Faster-RCNN-noAug   \n",
       "64     0.7  0.943117     0.897548   0.943203  0.943117  Faster-RCNN-noAug   \n",
       "65     0.8  0.932632     0.858044   0.930085  0.932632  Faster-RCNN-noAug   \n",
       "\n",
       "   cv_type  testset  model_id  \n",
       "0    loocv  Image10  ensemble  \n",
       "1    loocv  Image10  ensemble  \n",
       "2    loocv  Image10  ensemble  \n",
       "3    loocv  Image10  ensemble  \n",
       "4    loocv  Image10  ensemble  \n",
       "..     ...      ...       ...  \n",
       "61   loocv  average  ensemble  \n",
       "62   loocv  average  ensemble  \n",
       "63   loocv  average  ensemble  \n",
       "64   loocv  average  ensemble  \n",
       "65   loocv  average  ensemble  \n",
       "\n",
       "[66 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_loocv(\"Faster-RCNN-noAug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_cells(detection_result_file, thresh=0.7):\n",
    "    res_file = open(detection_result_file, \"r\")\n",
    "    detected_cells = [line.strip().split() for line in res_file]\n",
    "    n_valid_cell = len([cell for cell in detected_cells if float(cell[1]) > thresh])\n",
    "    avg_conf_score = np.nan if n_valid_cell == 0 else \\\n",
    "        \",\".join([str(cell[1]) for cell in detected_cells if float(cell[1]) > thresh])\n",
    "    return n_valid_cell, avg_conf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = pd.DataFrame()\n",
    "image_sets = [\"Image\" + str(i) for i in [1,2,3,5,6,7,8,9,10,11]]\n",
    "N = len(image_sets)\n",
    "\n",
    "for image_set in image_sets:\n",
    "    targets = pd.read_csv(\"crop_target/targets.csv\")\n",
    "    targets[\"image_set\"] = targets[\"image_id\"].apply(lambda x: x.split(\"_\")[0])\n",
    "    targets = targets[(targets.image_set == image_set) & ~targets.difficult]\n",
    "    \n",
    "    for thresh in [0, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]:\n",
    "        for model in [\"model1\", \"model2\", \"model3\", \"model4\", \"model5\"]:\n",
    "            targets_copy = targets.copy()\n",
    "            targets_copy[\"model\"] = model\n",
    "            targets_copy[\"thresh\"] = thresh\n",
    "            \n",
    "            num_cells, score_cells = [], []\n",
    "            for idx, target in targets_copy.iterrows():\n",
    "                image_id = target[\"image_id\"]\n",
    "                n_cells, avg_conf_score = count_cells(f\"Faster-RCNN-Ensemble/map_out/loocv/{image_set}/detection-results-{model}/{image_id}.txt\", thresh)\n",
    "                num_cells.append(n_cells)\n",
    "                score_cells.append(avg_conf_score)\n",
    "            targets_copy[\"num_cells\"] = num_cells\n",
    "            targets_copy[\"score_cells\"] = score_cells\n",
    "            records = pd.concat([records, targets_copy])\n",
    "            \n",
    "records.to_csv(\"./Figure_revision/supp_loocv_nCell_confScores_wThresh_labeler1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = pd.DataFrame()\n",
    "image_sets = [\"Image\" + str(i) for i in [1,2,3,5,6,7,8,9,10,11]]\n",
    "N = len(image_sets)\n",
    "\n",
    "for image_set in image_sets:\n",
    "    targets = pd.read_csv(\"crop_target/targets.csv\")\n",
    "    targets[\"image_set\"] = targets[\"image_id\"].apply(lambda x: x.split(\"_\")[0])\n",
    "    targets = targets[(targets.image_set == image_set) & ~targets.difficult]\n",
    "    \n",
    "    for thresh in [0, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]:\n",
    "        for model in [\"model1\", \"model2\", \"model3\", \"model4\", \"model5\"]:\n",
    "            targets_copy = targets.copy()\n",
    "            targets_copy[\"model\"] = model\n",
    "            targets_copy[\"thresh\"] = thresh\n",
    "            \n",
    "            num_cells, score_cells = [], []\n",
    "            for idx, target in targets_copy.iterrows():\n",
    "                image_id = target[\"image_id\"]\n",
    "                n_cells, avg_conf_score = count_cells(f\"Faster-RCNN-Xinya2Kaiwen/map_out/loocv/{image_set}/detection-results-{model}/{image_id}.txt\", thresh)\n",
    "                num_cells.append(n_cells)\n",
    "                score_cells.append(avg_conf_score)\n",
    "            targets_copy[\"num_cells\"] = num_cells\n",
    "            targets_copy[\"score_cells\"] = score_cells\n",
    "            records = pd.concat([records, targets_copy])\n",
    "            \n",
    "records.to_csv(\"./Figure_revision/supp_loocv_nCell_confScores_wThresh_labeler2to1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = pd.DataFrame()\n",
    "image_sets = [\"Image\" + str(i) for i in [1,2,3,5,7,8,9,10,11]]\n",
    "N = len(image_sets)\n",
    "\n",
    "for image_set in image_sets:\n",
    "    targets = pd.read_csv(\"crop_target/xinya_targets.csv\")\n",
    "    targets[\"image_set\"] = targets[\"image_id\"].apply(lambda x: x.split(\"_\")[0])\n",
    "    targets = targets[(targets.image_set == image_set) & ~targets.difficult]\n",
    "    \n",
    "    for thresh in [0, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]:\n",
    "        for model in [\"model1\", \"model2\", \"model3\", \"model4\", \"model5\"]:\n",
    "            targets_copy = targets.copy()\n",
    "            targets_copy[\"model\"] = model\n",
    "            targets_copy[\"thresh\"] = thresh\n",
    "            \n",
    "            num_cells, score_cells = [], []\n",
    "            for idx, target in targets_copy.iterrows():\n",
    "                image_id = target[\"image_id\"]\n",
    "                n_cells, avg_conf_score = count_cells(f\"Faster-RCNN-Ensemble-Xinya/map_out/loocv/{image_set}/detection-results-{model}/{image_id}.txt\", thresh)\n",
    "                num_cells.append(n_cells)\n",
    "                score_cells.append(avg_conf_score)\n",
    "            targets_copy[\"num_cells\"] = num_cells\n",
    "            targets_copy[\"score_cells\"] = score_cells\n",
    "            records = pd.concat([records, targets_copy])\n",
    "            \n",
    "records.to_csv(\"./Figure_revision/supp_loocv_nCell_confScores_wThresh_labeler2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = pd.DataFrame()\n",
    "image_sets = [\"Image\" + str(i) for i in [1,2,3,5,7,8,9,10,11]]\n",
    "N = len(image_sets)\n",
    "\n",
    "for image_set in image_sets:\n",
    "    targets = pd.read_csv(\"crop_target/xinya_targets.csv\")\n",
    "    targets[\"image_set\"] = targets[\"image_id\"].apply(lambda x: x.split(\"_\")[0])\n",
    "    targets = targets[(targets.image_set == image_set) & ~targets.difficult]\n",
    "    \n",
    "    for thresh in [0, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]:\n",
    "        for model in [\"model1\", \"model2\", \"model3\", \"model4\", \"model5\"]:\n",
    "            targets_copy = targets.copy()\n",
    "            targets_copy[\"model\"] = model\n",
    "            targets_copy[\"thresh\"] = thresh\n",
    "            \n",
    "            num_cells, score_cells = [], []\n",
    "            for idx, target in targets_copy.iterrows():\n",
    "                image_id = target[\"image_id\"]\n",
    "                n_cells, avg_conf_score = count_cells(f\"Faster-RCNN-Kaiwen2Xinya/map_out/loocv/{image_set}/detection-results-{model}/{image_id}.txt\", thresh)\n",
    "                num_cells.append(n_cells)\n",
    "                score_cells.append(avg_conf_score)\n",
    "            targets_copy[\"num_cells\"] = num_cells\n",
    "            targets_copy[\"score_cells\"] = score_cells\n",
    "            records = pd.concat([records, targets_copy])\n",
    "            \n",
    "records.to_csv(\"./Figure_revision/supp_loocv_nCell_confScores_wThresh_labeler1to2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_methods = {\n",
    "    \"method\": [],\n",
    "    \"settings\": [],\n",
    "    \"is_rmEmpty\": [],\n",
    "    \"f1_score\": [],\n",
    "}\n",
    "\n",
    "res_doubletdetection = sc.read_h5ad(\"./expression/results/DoubletDetection/doubletdetection_img5_noMissing.h5ad\")\n",
    "for k, v in res_doubletdetection.uns.items():\n",
    "    if k != \"hvg\":\n",
    "        res_methods[\"method\"].append(\"DoubletDetection\")\n",
    "        res_methods[\"settings\"].append(k)\n",
    "        res_methods[\"is_rmEmpty\"].append(True)\n",
    "        res_methods[\"f1_score\"].append(v[\"f1_score\"])\n",
    "res_doubletdetection = sc.read_h5ad(\"./expression/results/DoubletDetection/doubletdetection_img5.h5ad\")\n",
    "for k, v in res_doubletdetection.uns.items():\n",
    "    if k != \"hvg\":\n",
    "        res_methods[\"method\"].append(\"DoubletDetection\")\n",
    "        res_methods[\"settings\"].append(k)\n",
    "        res_methods[\"is_rmEmpty\"].append(False)\n",
    "        res_methods[\"f1_score\"].append(v[\"f1_score\"])\n",
    "        \n",
    "        \n",
    "res_scrublet = sc.read_h5ad(\"./expression/results/scrublet/scrublet_img5.h5ad\")\n",
    "for k, v in res_scrublet.uns.items():\n",
    "    if k != \"hvg\" and isinstance(v, dict):\n",
    "        res_methods[\"method\"].append(\"Scrublet\")\n",
    "        res_methods[\"settings\"].append(k)\n",
    "        res_methods[\"is_rmEmpty\"].append(False)\n",
    "        res_methods[\"f1_score\"].append(v[\"f1_score\"])\n",
    "res_scrublet = sc.read_h5ad(\"./expression/results/scrublet/scrublet_img5_noMissing.h5ad\")\n",
    "for k, v in res_scrublet.uns.items():\n",
    "    if k != \"hvg\" and isinstance(v, dict):\n",
    "        res_methods[\"method\"].append(\"Scrublet\")\n",
    "        res_methods[\"settings\"].append(k)\n",
    "        res_methods[\"is_rmEmpty\"].append(True)\n",
    "        res_methods[\"f1_score\"].append(v[\"f1_score\"])\n",
    "\n",
    "\n",
    "res_solo = sc.read_h5ad(\"./expression/results/solo/solo_img5.h5ad\")\n",
    "for k, v in res_solo.uns.items():\n",
    "    if k != \"hvg\" and isinstance(v, dict):\n",
    "        res_methods[\"method\"].append(\"Solo\")\n",
    "        res_methods[\"settings\"].append(k)\n",
    "        res_methods[\"is_rmEmpty\"].append(False)\n",
    "        res_methods[\"f1_score\"].append(v[\"f1_score\"])\n",
    "res_solo = sc.read_h5ad(\"./expression/results/solo/solo_img5_noMissing.h5ad\")\n",
    "for k, v in res_solo.uns.items():\n",
    "    if k != \"hvg\" and isinstance(v, dict):\n",
    "        res_methods[\"method\"].append(\"Solo\")\n",
    "        res_methods[\"settings\"].append(k)\n",
    "        res_methods[\"is_rmEmpty\"].append(True)\n",
    "        res_methods[\"f1_score\"].append(v[\"f1_score\"])\n",
    "\n",
    "\n",
    "res_socube = sc.read_h5ad(\"./expression/results/socube/socube_img5.h5ad\")\n",
    "for k, v in res_socube.uns.items():\n",
    "    if k != \"hvg\":\n",
    "        res_methods[\"method\"].append(\"SoCube\")\n",
    "        res_methods[\"settings\"].append(k)\n",
    "        res_methods[\"is_rmEmpty\"].append(False)\n",
    "        res_methods[\"f1_score\"].append(v[\"f1_score\"])\n",
    "res_socube = sc.read_h5ad(\"./expression/results/socube/socube_img5_noMissing.h5ad\")\n",
    "for k, v in res_socube.uns.items():\n",
    "    if k != \"hvg\":\n",
    "        res_methods[\"method\"].append(\"SoCube\")\n",
    "        res_methods[\"settings\"].append(k)\n",
    "        res_methods[\"is_rmEmpty\"].append(True)\n",
    "        res_methods[\"f1_score\"].append(v[\"f1_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_scDblFinder = pd.read_csv(\"./expression/results/scDblFinder/scDblFinder/scores.csv\", index_col=0)\n",
    "for idx, row in res_scDblFinder.iterrows():\n",
    "    if \"img5\" in idx:\n",
    "        res_methods[\"method\"].append(\"scDblFinder\")\n",
    "        res_methods[\"settings\"].append(idx)\n",
    "        res_methods[\"is_rmEmpty\"].append((\"noMissing\" in idx))\n",
    "        res_methods[\"f1_score\"].append(row[\"f1\"])\n",
    "\n",
    "res_scds = pd.read_csv(\"./expression/results/scds/scds/scores.csv\", index_col=0)\n",
    "for idx, row in res_scds.iterrows():\n",
    "    if \"img5\" in idx:\n",
    "        res_methods[\"method\"].append(\"scds\")\n",
    "        res_methods[\"settings\"].append(row[\"method\"] + \"_\" + str(row[\"thresh\"]))\n",
    "        res_methods[\"is_rmEmpty\"].append((\"noMissing\" in idx))\n",
    "        res_methods[\"f1_score\"].append(row[\"f1\"])\n",
    "        \n",
    "res_doubletfinder = pd.read_csv(\"./expression/results/DoubletFinder/DoubletFinder/scores.csv\", index_col=0)\n",
    "for idx, row in res_doubletfinder.iterrows():\n",
    "    if \"img5\" in idx:\n",
    "        res_methods[\"method\"].append(\"DoubletFinder\")\n",
    "        res_methods[\"settings\"].append(idx)\n",
    "        res_methods[\"is_rmEmpty\"].append((\"noMissing\" in idx))\n",
    "        res_methods[\"f1_score\"].append(row[\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(res_methods).to_csv(\"./Figure_revision/supp_doublet_detection_f1_score_img5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_methods = {\n",
    "    \"method\": [],\n",
    "    \"settings\": [],\n",
    "    \"is_rmEmpty\": [],\n",
    "    \"f1_score\": [],\n",
    "}\n",
    "\n",
    "res_doubletdetection = sc.read_h5ad(\"./expression/results/DoubletDetection/doubletdetection_img11_noMissing.h5ad\")\n",
    "for k, v in res_doubletdetection.uns.items():\n",
    "    if k != \"hvg\":\n",
    "        res_methods[\"method\"].append(\"DoubletDetection\")\n",
    "        res_methods[\"settings\"].append(k)\n",
    "        res_methods[\"is_rmEmpty\"].append(True)\n",
    "        res_methods[\"f1_score\"].append(v[\"f1_score\"])\n",
    "res_doubletdetection = sc.read_h5ad(\"./expression/results/DoubletDetection/doubletdetection_img11.h5ad\")\n",
    "for k, v in res_doubletdetection.uns.items():\n",
    "    if k != \"hvg\":\n",
    "        res_methods[\"method\"].append(\"DoubletDetection\")\n",
    "        res_methods[\"settings\"].append(k)\n",
    "        res_methods[\"is_rmEmpty\"].append(False)\n",
    "        res_methods[\"f1_score\"].append(v[\"f1_score\"])\n",
    "        \n",
    "        \n",
    "res_scrublet = sc.read_h5ad(\"./expression/results/scrublet/scrublet_img11.h5ad\")\n",
    "for k, v in res_scrublet.uns.items():\n",
    "    if k != \"hvg\" and isinstance(v, dict):\n",
    "        res_methods[\"method\"].append(\"Scrublet\")\n",
    "        res_methods[\"settings\"].append(k)\n",
    "        res_methods[\"is_rmEmpty\"].append(False)\n",
    "        res_methods[\"f1_score\"].append(v[\"f1_score\"])\n",
    "res_scrublet = sc.read_h5ad(\"./expression/results/scrublet/scrublet_img11_noMissing.h5ad\")\n",
    "for k, v in res_scrublet.uns.items():\n",
    "    if k != \"hvg\" and isinstance(v, dict):\n",
    "        res_methods[\"method\"].append(\"Scrublet\")\n",
    "        res_methods[\"settings\"].append(k)\n",
    "        res_methods[\"is_rmEmpty\"].append(True)\n",
    "        res_methods[\"f1_score\"].append(v[\"f1_score\"])\n",
    "\n",
    "\n",
    "res_solo = sc.read_h5ad(\"./expression/results/solo/solo_img11.h5ad\")\n",
    "for k, v in res_solo.uns.items():\n",
    "    if k != \"hvg\" and isinstance(v, dict):\n",
    "        res_methods[\"method\"].append(\"Solo\")\n",
    "        res_methods[\"settings\"].append(k)\n",
    "        res_methods[\"is_rmEmpty\"].append(False)\n",
    "        res_methods[\"f1_score\"].append(v[\"f1_score\"])\n",
    "res_solo = sc.read_h5ad(\"./expression/results/solo/solo_img11_noMissing.h5ad\")\n",
    "for k, v in res_solo.uns.items():\n",
    "    if k != \"hvg\" and isinstance(v, dict):\n",
    "        res_methods[\"method\"].append(\"Solo\")\n",
    "        res_methods[\"settings\"].append(k)\n",
    "        res_methods[\"is_rmEmpty\"].append(True)\n",
    "        res_methods[\"f1_score\"].append(v[\"f1_score\"])\n",
    "\n",
    "\n",
    "res_socube = sc.read_h5ad(\"./expression/results/socube/socube_img11.h5ad\")\n",
    "for k, v in res_socube.uns.items():\n",
    "    if k != \"hvg\":\n",
    "        res_methods[\"method\"].append(\"SoCube\")\n",
    "        res_methods[\"settings\"].append(k)\n",
    "        res_methods[\"is_rmEmpty\"].append(False)\n",
    "        res_methods[\"f1_score\"].append(v[\"f1_score\"])\n",
    "res_socube = sc.read_h5ad(\"./expression/results/socube/socube_img11_noMissing.h5ad\")\n",
    "for k, v in res_socube.uns.items():\n",
    "    if k != \"hvg\":\n",
    "        res_methods[\"method\"].append(\"SoCube\")\n",
    "        res_methods[\"settings\"].append(k)\n",
    "        res_methods[\"is_rmEmpty\"].append(True)\n",
    "        res_methods[\"f1_score\"].append(v[\"f1_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_scDblFinder = pd.read_csv(\"./expression/results/scDblFinder/scDblFinder/scores.csv\", index_col=0)\n",
    "for idx, row in res_scDblFinder.iterrows():\n",
    "    if \"img11\" in idx:\n",
    "        res_methods[\"method\"].append(\"scDblFinder\")\n",
    "        res_methods[\"settings\"].append(idx)\n",
    "        res_methods[\"is_rmEmpty\"].append((\"noMissing\" in idx))\n",
    "        res_methods[\"f1_score\"].append(row[\"f1\"])\n",
    "\n",
    "res_scds = pd.read_csv(\"./expression/results/scds/scds/scores.csv\", index_col=0)\n",
    "for idx, row in res_scds.iterrows():\n",
    "    if \"img11\" in idx:\n",
    "        res_methods[\"method\"].append(\"scds\")\n",
    "        res_methods[\"settings\"].append(row[\"method\"] + \"_\" + str(row[\"thresh\"]))\n",
    "        res_methods[\"is_rmEmpty\"].append((\"noMissing\" in idx))\n",
    "        res_methods[\"f1_score\"].append(row[\"f1\"])\n",
    "        \n",
    "res_doubletfinder = pd.read_csv(\"./expression/results/DoubletFinder/DoubletFinder/scores.csv\", index_col=0)\n",
    "for idx, row in res_doubletfinder.iterrows():\n",
    "    if \"img11\" in idx:\n",
    "        res_methods[\"method\"].append(\"DoubletFinder\")\n",
    "        res_methods[\"settings\"].append(idx)\n",
    "        res_methods[\"is_rmEmpty\"].append((\"noMissing\" in idx))\n",
    "        res_methods[\"f1_score\"].append(row[\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(res_methods).to_csv(\"./Figure_revision/supp_doublet_detection_f1_score_img11.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_methods = {\n",
    "    \"method\": [],\n",
    "    \"settings\": [],\n",
    "    \"is_rmEmpty\": [],\n",
    "    \"f1_score\": [],\n",
    "}\n",
    "            \n",
    "res_scrublet = sc.read_h5ad(\"./expression/results/scrublet/scrublet_imgExtra.h5ad\")\n",
    "for k, v in res_scrublet.uns.items():\n",
    "    if k != \"hvg\" and isinstance(v, dict):\n",
    "        res_methods[\"method\"].append(\"Scrublet\")\n",
    "        res_methods[\"settings\"].append(k)\n",
    "        res_methods[\"is_rmEmpty\"].append(False)\n",
    "        res_methods[\"f1_score\"].append(v[\"f1_score\"])\n",
    "res_scrublet = sc.read_h5ad(\"./expression/results/scrublet/scrublet_imgExtra_noMissing.h5ad\")\n",
    "for k, v in res_scrublet.uns.items():\n",
    "    if k != \"hvg\" and isinstance(v, dict):\n",
    "        res_methods[\"method\"].append(\"Scrublet\")\n",
    "        res_methods[\"settings\"].append(k)\n",
    "        res_methods[\"is_rmEmpty\"].append(True)\n",
    "        res_methods[\"f1_score\"].append(v[\"f1_score\"])\n",
    "\n",
    "\n",
    "res_solo = sc.read_h5ad(\"./expression/results/solo/solo_imgExtra.h5ad\")\n",
    "for k, v in res_solo.uns.items():\n",
    "    if k != \"hvg\" and isinstance(v, dict):\n",
    "        res_methods[\"method\"].append(\"Solo\")\n",
    "        res_methods[\"settings\"].append(k)\n",
    "        res_methods[\"is_rmEmpty\"].append(False)\n",
    "        res_methods[\"f1_score\"].append(v[\"f1_score\"])\n",
    "res_solo = sc.read_h5ad(\"./expression/results/solo/solo_imgExtra_noMissing.h5ad\")\n",
    "for k, v in res_solo.uns.items():\n",
    "    if k != \"hvg\" and isinstance(v, dict):\n",
    "        res_methods[\"method\"].append(\"Solo\")\n",
    "        res_methods[\"settings\"].append(k)\n",
    "        res_methods[\"is_rmEmpty\"].append(True)\n",
    "        res_methods[\"f1_score\"].append(v[\"f1_score\"])\n",
    "\n",
    "\n",
    "res_socube = sc.read_h5ad(\"./expression/results/socube/socube_imgExtra.h5ad\")\n",
    "for k, v in res_socube.uns.items():\n",
    "    if k != \"hvg\":\n",
    "        res_methods[\"method\"].append(\"SoCube\")\n",
    "        res_methods[\"settings\"].append(k)\n",
    "        res_methods[\"is_rmEmpty\"].append(False)\n",
    "        res_methods[\"f1_score\"].append(v[\"f1_score\"])\n",
    "res_socube = sc.read_h5ad(\"./expression/results/socube/socube_imgExtra_noMissing.h5ad\")\n",
    "for k, v in res_socube.uns.items():\n",
    "    if k != \"hvg\":\n",
    "        res_methods[\"method\"].append(\"SoCube\")\n",
    "        res_methods[\"settings\"].append(k)\n",
    "        res_methods[\"is_rmEmpty\"].append(True)\n",
    "        res_methods[\"f1_score\"].append(v[\"f1_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>settings</th>\n",
       "      <th>is_rmEmpty</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scrublet</td>\n",
       "      <td>eva_doublets_thresh_0.20</td>\n",
       "      <td>False</td>\n",
       "      <td>0.430769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scrublet</td>\n",
       "      <td>eva_doublets_thresh_0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scrublet</td>\n",
       "      <td>eva_doublets_thresh_0.30</td>\n",
       "      <td>False</td>\n",
       "      <td>0.410959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Scrublet</td>\n",
       "      <td>eva_doublets_thresh_0.35</td>\n",
       "      <td>False</td>\n",
       "      <td>0.403270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scrublet</td>\n",
       "      <td>eva_doublets_thresh_0.40</td>\n",
       "      <td>False</td>\n",
       "      <td>0.328671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Scrublet</td>\n",
       "      <td>eva_doublets_thresh_0.45</td>\n",
       "      <td>False</td>\n",
       "      <td>0.258333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Scrublet</td>\n",
       "      <td>eva_doublets_thresh_0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Scrublet</td>\n",
       "      <td>eva_doublets_thresh_0.55</td>\n",
       "      <td>False</td>\n",
       "      <td>0.116959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Scrublet</td>\n",
       "      <td>eva_doublets_thresh_0.60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.050314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Scrublet</td>\n",
       "      <td>eva_doublets_thresh_0.20</td>\n",
       "      <td>True</td>\n",
       "      <td>0.428822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Scrublet</td>\n",
       "      <td>eva_doublets_thresh_0.25</td>\n",
       "      <td>True</td>\n",
       "      <td>0.421663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Scrublet</td>\n",
       "      <td>eva_doublets_thresh_0.30</td>\n",
       "      <td>True</td>\n",
       "      <td>0.411379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Scrublet</td>\n",
       "      <td>eva_doublets_thresh_0.35</td>\n",
       "      <td>True</td>\n",
       "      <td>0.368000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Scrublet</td>\n",
       "      <td>eva_doublets_thresh_0.40</td>\n",
       "      <td>True</td>\n",
       "      <td>0.323024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Scrublet</td>\n",
       "      <td>eva_doublets_thresh_0.45</td>\n",
       "      <td>True</td>\n",
       "      <td>0.267717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Scrublet</td>\n",
       "      <td>eva_doublets_thresh_0.50</td>\n",
       "      <td>True</td>\n",
       "      <td>0.234234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Scrublet</td>\n",
       "      <td>eva_doublets_thresh_0.55</td>\n",
       "      <td>True</td>\n",
       "      <td>0.152174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Scrublet</td>\n",
       "      <td>eva_doublets_thresh_0.60</td>\n",
       "      <td>True</td>\n",
       "      <td>0.061350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Solo</td>\n",
       "      <td>eva_min_cells_0_n_top_genes_2000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.336043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Solo</td>\n",
       "      <td>eva_min_cells_0_n_top_genes_5000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.377358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Solo</td>\n",
       "      <td>eva_min_cells_0_n_top_genes_all</td>\n",
       "      <td>False</td>\n",
       "      <td>0.279863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Solo</td>\n",
       "      <td>eva_min_cells_10_n_top_genes_2000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.376190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Solo</td>\n",
       "      <td>eva_min_cells_10_n_top_genes_5000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.354680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Solo</td>\n",
       "      <td>eva_min_cells_10_n_top_genes_all</td>\n",
       "      <td>False</td>\n",
       "      <td>0.358543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Solo</td>\n",
       "      <td>eva_min_cells_1_n_top_genes_2000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.380048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Solo</td>\n",
       "      <td>eva_min_cells_1_n_top_genes_5000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.385882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Solo</td>\n",
       "      <td>eva_min_cells_1_n_top_genes_all</td>\n",
       "      <td>False</td>\n",
       "      <td>0.349057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Solo</td>\n",
       "      <td>eva_min_cells_0_n_top_genes_2000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.356021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Solo</td>\n",
       "      <td>eva_min_cells_0_n_top_genes_5000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.340852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Solo</td>\n",
       "      <td>eva_min_cells_0_n_top_genes_all</td>\n",
       "      <td>True</td>\n",
       "      <td>0.276596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Solo</td>\n",
       "      <td>eva_min_cells_10_n_top_genes_2000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.355795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Solo</td>\n",
       "      <td>eva_min_cells_10_n_top_genes_5000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.336585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Solo</td>\n",
       "      <td>eva_min_cells_10_n_top_genes_all</td>\n",
       "      <td>True</td>\n",
       "      <td>0.348485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Solo</td>\n",
       "      <td>eva_min_cells_1_n_top_genes_2000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.348668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Solo</td>\n",
       "      <td>eva_min_cells_1_n_top_genes_5000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.345499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Solo</td>\n",
       "      <td>eva_min_cells_1_n_top_genes_all</td>\n",
       "      <td>True</td>\n",
       "      <td>0.365217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SoCube</td>\n",
       "      <td>eva_0.3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.280936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SoCube</td>\n",
       "      <td>eva_0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.279245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SoCube</td>\n",
       "      <td>eva_0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.270042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SoCube</td>\n",
       "      <td>eva_0.6</td>\n",
       "      <td>False</td>\n",
       "      <td>0.242152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SoCube</td>\n",
       "      <td>eva_0.7</td>\n",
       "      <td>False</td>\n",
       "      <td>0.187192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SoCube</td>\n",
       "      <td>eva_0.3</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SoCube</td>\n",
       "      <td>eva_0.4</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>SoCube</td>\n",
       "      <td>eva_0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>SoCube</td>\n",
       "      <td>eva_0.6</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>SoCube</td>\n",
       "      <td>eva_0.7</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      method                           settings  is_rmEmpty  f1_score\n",
       "0   Scrublet           eva_doublets_thresh_0.20       False  0.430769\n",
       "1   Scrublet           eva_doublets_thresh_0.25       False  0.434783\n",
       "2   Scrublet           eva_doublets_thresh_0.30       False  0.410959\n",
       "3   Scrublet           eva_doublets_thresh_0.35       False  0.403270\n",
       "4   Scrublet           eva_doublets_thresh_0.40       False  0.328671\n",
       "5   Scrublet           eva_doublets_thresh_0.45       False  0.258333\n",
       "6   Scrublet           eva_doublets_thresh_0.50       False  0.153846\n",
       "7   Scrublet           eva_doublets_thresh_0.55       False  0.116959\n",
       "8   Scrublet           eva_doublets_thresh_0.60       False  0.050314\n",
       "9   Scrublet           eva_doublets_thresh_0.20        True  0.428822\n",
       "10  Scrublet           eva_doublets_thresh_0.25        True  0.421663\n",
       "11  Scrublet           eva_doublets_thresh_0.30        True  0.411379\n",
       "12  Scrublet           eva_doublets_thresh_0.35        True  0.368000\n",
       "13  Scrublet           eva_doublets_thresh_0.40        True  0.323024\n",
       "14  Scrublet           eva_doublets_thresh_0.45        True  0.267717\n",
       "15  Scrublet           eva_doublets_thresh_0.50        True  0.234234\n",
       "16  Scrublet           eva_doublets_thresh_0.55        True  0.152174\n",
       "17  Scrublet           eva_doublets_thresh_0.60        True  0.061350\n",
       "18      Solo   eva_min_cells_0_n_top_genes_2000       False  0.336043\n",
       "19      Solo   eva_min_cells_0_n_top_genes_5000       False  0.377358\n",
       "20      Solo    eva_min_cells_0_n_top_genes_all       False  0.279863\n",
       "21      Solo  eva_min_cells_10_n_top_genes_2000       False  0.376190\n",
       "22      Solo  eva_min_cells_10_n_top_genes_5000       False  0.354680\n",
       "23      Solo   eva_min_cells_10_n_top_genes_all       False  0.358543\n",
       "24      Solo   eva_min_cells_1_n_top_genes_2000       False  0.380048\n",
       "25      Solo   eva_min_cells_1_n_top_genes_5000       False  0.385882\n",
       "26      Solo    eva_min_cells_1_n_top_genes_all       False  0.349057\n",
       "27      Solo   eva_min_cells_0_n_top_genes_2000        True  0.356021\n",
       "28      Solo   eva_min_cells_0_n_top_genes_5000        True  0.340852\n",
       "29      Solo    eva_min_cells_0_n_top_genes_all        True  0.276596\n",
       "30      Solo  eva_min_cells_10_n_top_genes_2000        True  0.355795\n",
       "31      Solo  eva_min_cells_10_n_top_genes_5000        True  0.336585\n",
       "32      Solo   eva_min_cells_10_n_top_genes_all        True  0.348485\n",
       "33      Solo   eva_min_cells_1_n_top_genes_2000        True  0.348668\n",
       "34      Solo   eva_min_cells_1_n_top_genes_5000        True  0.345499\n",
       "35      Solo    eva_min_cells_1_n_top_genes_all        True  0.365217\n",
       "36    SoCube                            eva_0.3       False  0.280936\n",
       "37    SoCube                            eva_0.4       False  0.279245\n",
       "38    SoCube                            eva_0.5       False  0.270042\n",
       "39    SoCube                            eva_0.6       False  0.242152\n",
       "40    SoCube                            eva_0.7       False  0.187192\n",
       "41    SoCube                            eva_0.3        True       NaN\n",
       "42    SoCube                            eva_0.4        True       NaN\n",
       "43    SoCube                            eva_0.5        True       NaN\n",
       "44    SoCube                            eva_0.6        True       NaN\n",
       "45    SoCube                            eva_0.7        True       NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(res_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_image_based = sc.read_h5ad(\"./expression/results/image-based/adata_img5_wPreds.h5ad\")\n",
    "res_image_based = res_image_based[res_image_based.obs[\"class\"].notnull() &\n",
    "                                  (res_image_based.obs[\"difficult\"] == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6482/960634794.py:1: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  res_image_based.obs[\"isMissing\"] = (res_image_based.obs[\"class\"] == \"Missing\").astype(int)\n"
     ]
    }
   ],
   "source": [
    "res_image_based.obs[\"isMissing\"] = (res_image_based.obs[\"class\"] == \"Missing\").astype(int)\n",
    "res_image_based.obs[\"isMissing_pred\"] = (res_image_based.obs[\"pred_image_class\"] == \"Missing\").astype(int)\n",
    "f1_image_based = f1_score(res_image_based.obs[\"isMissing\"], res_image_based.obs[\"isMissing_pred\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9847715736040609"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_image_based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
